{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class PostgresPipeline:\n",
    "    def __init__(self, db_config):\n",
    "        self.db_config = db_config\n",
    "        self.conn = None\n",
    "        self.cur = None\n",
    "        self.connect()\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.conn = psycopg2.connect(**self.db_config)\n",
    "            self.conn.set_session(autocommit=True)\n",
    "            self.cur = self.conn.cursor()\n",
    "            print(\"Database connection established.\")\n",
    "        except psycopg2.Error as e:\n",
    "            print(f\"Error: Could not connect to the database. {e}\")\n",
    "            self.conn = None\n",
    "\n",
    "    def create_table(self, table_name, columns, foreign_keys=None):\n",
    "        column_defs = [f\"{col} {dtype}\" for col, dtype in columns.items()]\n",
    "        if foreign_keys:\n",
    "            column_defs.extend(foreign_keys)\n",
    "        create_table_sql = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            {', '.join(column_defs)}\n",
    "        );\n",
    "        \"\"\"\n",
    "        self.execute_query(create_table_sql)\n",
    "        print(f\"Table '{table_name}' created or already exists.\")\n",
    "\n",
    "    def alter_table(self, table_name, columns):\n",
    "        \"\"\"\n",
    "        Alter table by adding new columns if they do not exist.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for col, dtype in columns.items():\n",
    "                alter_query = f\"\"\"\n",
    "                ALTER TABLE {table_name}\n",
    "                ADD COLUMN IF NOT EXISTS {col} {dtype};\n",
    "                \"\"\"\n",
    "                self.cur.execute(alter_query)\n",
    "                print(f\"‚úÖ Column '{col}' added to '{table_name}' (if not exists).\")\n",
    "\n",
    "            # ‚úÖ Commit changes to the database\n",
    "            self.conn.commit()\n",
    "\n",
    "        except psycopg2.Error as e:\n",
    "            print(f\"‚ùå Error altering table '{table_name}': {e}\")\n",
    "\n",
    "    def load_csv_to_table(self, csv_path, table_name, columns):\n",
    "        try:\n",
    "            with open(csv_path, 'r') as f:\n",
    "                self.cur.copy_expert(\n",
    "                    f\"\"\"\n",
    "                    COPY {table_name} ({', '.join(columns)})\n",
    "                    FROM STDIN\n",
    "                    WITH (FORMAT CSV, HEADER TRUE);\n",
    "                    \"\"\", f\n",
    "                )\n",
    "            print(f\"Data loaded into table '{table_name}' from '{csv_path}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data into table '{table_name}': {e}\")\n",
    "\n",
    "    def execute_query(self, query):\n",
    "        try:\n",
    "            self.cur.execute(query)\n",
    "            print(\"Query executed successfully.\")\n",
    "        except psycopg2.Error as e:\n",
    "            print(f\"Error executing query: {e}\")\n",
    "\n",
    "    def fetch_all(self, query):\n",
    "        try:\n",
    "            self.cur.execute(query)\n",
    "            return self.cur.fetchall()\n",
    "        except psycopg2.Error as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            return []\n",
    "\n",
    "    # Utility to generate a sample CSV file\n",
    "    def generate_sample_csv(self, csv_path, num_rows, columns):\n",
    "        \"\"\"\n",
    "        Generate a sample CSV file for chat history.\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for _ in range(num_rows):\n",
    "          row = {col: random.choice(vals) for col, vals in columns.items()}\n",
    "        rows.append(row)\n",
    "        df = pd.DataFrame(rows)  # Create DataFrame from the list of rows\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Sample CSV file generated at '{csv_path}'.\")\n",
    "\n",
    "    def insert_data(self, table_name, columns, data):\n",
    "        try:\n",
    "            column_names = ', '.join(columns.keys())\n",
    "            placeholders = ', '.join(['%s' for _ in columns])\n",
    "            insert_sql = f\"\"\"\n",
    "            INSERT INTO {table_name} ({column_names})\n",
    "            VALUES ({placeholders});\n",
    "            \"\"\"\n",
    "            self.cur.execute(insert_sql, (data,))\n",
    "            print(\"Data inserted successfully.\")\n",
    "        except psycopg2.Error as e:\n",
    "            print(f\"Error inserting data: {e}\")\n",
    "\n",
    "    def create_chat_history_csv(self, csv_path, num_rows):\n",
    "        columns = {\n",
    "            'user_id': [1, 2, 3],\n",
    "            'message': ['hello', 'hi', 'hey'],\n",
    "            \"response\": ['hello', 'hi', 'hey'],\n",
    "            'timestamp': [datetime.now().strftime('%Y-%m-%d %H:%M:%S') for _ in range(num_rows)]\n",
    "        }\n",
    "        self.generate_sample_csv(csv_path, num_rows, columns)\n",
    "\n",
    "        # prepare data\n",
    "        data = [(\n",
    "            random.choice(columns['user_id']),\n",
    "            random.choice(columns['message']),\n",
    "            random.choice(columns['response']),\n",
    "            random.choice(columns['timestamp'])\n",
    "        )\n",
    "                for _ in range(num_rows)]\n",
    "        return data\n",
    "\n",
    "    def close(self):\n",
    "        if self.cur:\n",
    "            self.cur.close()\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "        print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    DB_CONFIG = {\n",
    "      \"host\": os.getenv(\"POSTGRES_HOST\"),\n",
    "      \"port\": os.getenv(\"POSTGRES_PORT\"),\n",
    "      \"database\": os.getenv(\"POSTGRES_DB\"),\n",
    "      \"user\": os.getenv(\"POSTGRES_USER\"),\n",
    "      \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    }\n",
    "\n",
    "    pipeline = PostgresPipeline(DB_CONFIG)\n",
    "\n",
    "\n",
    "\n",
    "    # Columns to movies table\n",
    "    MOVIES_TABLE = \"movies\"\n",
    "    MOVIES_COLUMNS = {\n",
    "        \"release_date\": \"DATE\",\n",
    "        \"poster_url\": \"TEXT\",\n",
    "        \"description\": \"TEXT\",\n",
    "        \"vote_average\": \"FLOAT\",\n",
    "        \"links\": \"TEXT\",\n",
    "    }\n",
    "\n",
    "    # Create movies table\n",
    "    pipeline.alter_table(MOVIES_TABLE, MOVIES_COLUMNS)\n",
    "\n",
    "    result = pipeline.fetch_all(f\"SELECT * FROM {MOVIES_TABLE}\")\n",
    "    print(\"üîç Chat History Data:\")\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of PostgresPipeline\n",
    "if __name__ == \"__main__\":\n",
    "    # Database connection details\n",
    "   DB_CONFIG = {\n",
    "    \"dbname\": os.getenv(\"POSTGRES_DB\"),\n",
    "    \"user\": os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"POSTGRES_HOST\"),\n",
    "    \"port\": os.getenv(\"POSTGRES_PORT\"),\n",
    "    }\n",
    "\n",
    "    # Create instance of PostgresPipeline\n",
    "pipeline = PostgresPipeline(DB_CONFIG)\n",
    "\n",
    "    # Close the connection\n",
    "pipeline.close()\n",
    "\n",
    "    # Check if the connection is closed\n",
    "print(pipeline.conn)\n",
    "\n",
    "    # Check if the cursor is closed\n",
    "print(pipeline.cur)\n",
    "\n",
    "    # Reconnect\n",
    "pipeline.connect()\n",
    "\n",
    "    # Test the connection\n",
    "print(pipeline.conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = fetch_movies(pipeline, 5)\n",
    "ratings = fetch_ratings(pipeline, 5)\n",
    "tags = fetch_tags(pipeline, 5)\n",
    "links = fetch_links(pipeline, 5)\n",
    "\n",
    "print(movies)\n",
    "print(ratings)\n",
    "print(tags)\n",
    "print(links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
